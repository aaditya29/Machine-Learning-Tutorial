{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Approaches to Making a Better ML Model\n",
    "\n",
    "1. More high-quality data.\n",
    "2. Hyperparameter tuning of algorithm.\n",
    "3. Trying different algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting from Previous Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  5.06 degrees.\n",
      "Average model error: 3.87 degrees.\n",
      "Improvement over baseline: 23.45 %.\n",
      "Accuracy: 93.93 %.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading in data as pandas dataframe and display first 5 rows\n",
    "original_features = pd.read_csv('./temps.csv')\n",
    "original_features = pd.get_dummies(original_features)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "original_labels = np.array(original_features['actual'])\n",
    "\n",
    "# Removing the labels from the features\n",
    "original_features = original_features.drop('actual', axis=1)  # axis 1 refers to the columns\n",
    "\n",
    "\n",
    "# Saving feature names for later use\n",
    "original_feature_list = list(original_features.columns)\n",
    "\n",
    "# Converting to numpy array\n",
    "original_features = np.array(original_features)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "original_train_features, original_test_features, original_train_labels, original_test_labels = train_test_split(original_features, original_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = original_test_features[:, original_feature_list.index('average')]\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - original_test_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Training the model on training data\n",
    "rf.fit(original_train_features, original_train_labels)\n",
    "\n",
    "# Using the forest's predict method on the test data\n",
    "predictions = rf.predict(original_test_features)\n",
    "\n",
    "# Calculating the absolute errors\n",
    "errors = abs(predictions - original_test_labels)\n",
    "\n",
    "# Printing out the mean absolute error (mae)\n",
    "print('Average model error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Comparing to baseline\n",
    "improvement_baseline = 100 * abs(np.mean(errors) - np.mean(baseline_errors)) / np.mean(baseline_errors)\n",
    "print('Improvement over baseline:', round(improvement_baseline, 2), '%.')\n",
    "\n",
    "# Calculating mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / original_test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
