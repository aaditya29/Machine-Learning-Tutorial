{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent in Python Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is a popular optimization algorithm used for finding the minimum of a function. It is widely used in machine learning and deep learning for training models. Here's why gradient descent is commonly used:\n",
    "\n",
    "1. **Efficiency**: Gradient descent can handle large datasets and high-dimensional parameter spaces efficiently. Unlike some other optimization methods, it does not require the computation of second-order derivatives (like Hessian matrices), making it less computationally expensive.\n",
    "\n",
    "2. **Scalability**: It can be applied to a wide range of problems, from linear regression and logistic regression to deep neural networks. Its iterative nature allows it to scale well with the size of the data and the complexity of the models.\n",
    "\n",
    "3. **Adaptability**: Gradient descent can be adapted to various optimization scenarios. For instance, Stochastic Gradient Descent (SGD) and its variants (like Mini-batch Gradient Descent, Momentum, RMSprop, Adam) introduce modifications that can improve convergence speed and stability, making the algorithm adaptable to different types of problems and data distributions.\n",
    "\n",
    "4. **Convergence**: Given an appropriate learning rate and sufficient iterations, gradient descent can converge to a local or global minimum. Properly chosen learning rates and strategies like learning rate annealing or adaptive learning rates (as in Adam optimizer) can enhance the convergence properties.\n",
    "\n",
    "5. **Simplicity**: The algorithm is relatively simple to implement and understand. The basic concept involves updating parameters in the opposite direction of the gradient of the loss function with respect to the parameters. This simplicity makes it a go-to choice for many practical machine learning applications.\n",
    "\n",
    "6. **Flexibility**: It can be used with different types of loss functions, making it versatile for various machine learning tasks, including classification, regression, and even unsupervised learning tasks.\n",
    "\n",
    "### Basic Concept\n",
    "\n",
    "The core idea of gradient descent is to iteratively adjust the parameters of the model to minimize the loss function, which measures the error between the model's predictions and the actual data. The adjustment is done in the direction opposite to the gradient of the loss function with respect to the parameters, which points in the direction of the steepest ascent. By moving in the opposite direction, the algorithm seeks the steepest descent.\n",
    "\n",
    "### Steps of Gradient Descent\n",
    "\n",
    "1. **Initialize Parameters**: Start with initial guesses for the parameters.\n",
    "2. **Compute Gradient**: Calculate the gradient of the loss function with respect to each parameter.\n",
    "3. **Update Parameters**: Adjust the parameters by subtracting the product of the gradient and the learning rate from the current parameters.\n",
    "4. **Iterate**: Repeat the process until convergence, i.e., until the change in the loss function is below a certain threshold or for a predetermined number of iterations.\n",
    "\n",
    "### Example\n",
    "\n",
    "For a simple linear regression problem, the parameters would be the weights and bias of the linear model. The loss function could be the Mean Squared Error (MSE) between the predicted values and the actual values. Gradient descent would iteratively adjust the weights and bias to minimize the MSE.\n",
    "\n",
    "In summary, gradient descent is used because it is a powerful, efficient, and versatile optimization algorithm suitable for a wide range of machine learning tasks. Its ability to handle large-scale problems and adapt to different types of data and models makes it a foundational tool in the field of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics of Gradient Descent\n",
    "\n",
    "### 1. Loss Function\n",
    "\n",
    "The first step in understanding gradient descent is to define the loss function. This function measures how well the model's predictions match the actual data. For simplicity, let's consider a linear regression problem where we try to fit a line to a set of data points.\n",
    "\n",
    "For a linear regression model $( y = wx + b )$, the loss function is often the Mean Squared Error (MSE):\n",
    "\n",
    "$[ L(w, b) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (wx_i + b))^2 ]$\n",
    "\n",
    "Here:\n",
    "- $( n )$ is the number of data points.\n",
    "- $( y_i )$ is the actual value.\n",
    "- $( x_i )$ is the input feature.\n",
    "- $( w )$ is the weight.\n",
    "- $( b )$ is the bias.\n",
    "\n",
    "### 2. Gradient of the Loss Function\n",
    "\n",
    "Gradient descent aims to find the minimum of the loss function. To do this, we compute the gradient of the loss function with respect to the parameters $( w )$ and $( b )$. The gradient is a vector of partial derivatives that point in the direction of the steepest ascent of the loss function.\n",
    "\n",
    "The partial derivatives of the MSE loss function with respect to $( w )$ and $( b )$ are:\n",
    "\n",
    "$[ \\frac{\\partial L}{\\partial w} = -\\frac{2}{n} \\sum_{i=1}^{n} x_i (y_i - (wx_i + b)) ]$\n",
    "\n",
    "$[ \\frac{\\partial L}{\\partial b} = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - (wx_i + b)) ]$\n",
    "\n",
    "### 3. Update Rule\n",
    "\n",
    "In gradient descent, we update the parameters in the direction opposite to the gradient. This is done iteratively using the following update rules:\n",
    "\n",
    "$[ w_{\\text{new}} = w_{\\text{old}} - \\alpha \\frac{\\partial L}{\\partial w} ]$\n",
    "\n",
    "$[ b_{\\text{new}} = b_{\\text{old}} - \\alpha \\frac{\\partial L}{\\partial b} ]$\n",
    "\n",
    "Here, $( \\alpha )$ is the learning rate, a small positive number that controls the step size of the update.\n",
    "\n",
    "### 4. Iterative Process\n",
    "\n",
    "1. **Initialize** the parameters $( w )$ and $( b )$ with some values (often random or zeros).\n",
    "2. **Compute the gradient** of the loss function with respect to $( w )$ and $( b )$.\n",
    "3. **Update the parameters** using the update rules.\n",
    "4. **Repeat** steps 2 and 3 until the parameters converge to values that minimize the loss function.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's go through a simple example with one data point for illustration:\n",
    "\n",
    "- Data point: $( (x, y) = (2, 4) )$\n",
    "- Initial parameters: $( w = 0 )$, $( b = 0 )$\n",
    "- Learning rate: $( \\alpha = 0.01 )$\n",
    "\n",
    "#### Step-by-Step Calculation\n",
    "\n",
    "1. **Compute the prediction**:\n",
    "\n",
    "   $[ \\hat{y} = wx + b = 0 \\cdot 2 + 0 = 0 ]$\n",
    "\n",
    "2. **Compute the loss**:\n",
    "\n",
    "   $[ L = (y - \\hat{y})^2 = (4 - 0)^2 = 16 ]$\n",
    "\n",
    "3. **Compute the gradients**:\n",
    "\n",
    "   $[ \\frac{\\partial L}{\\partial w} = -2x(y - (wx + b)) = -2 \\cdot 2 \\cdot (4 - 0) = -16 ]$\n",
    "\n",
    "   $[ \\frac{\\partial L}{\\partial b} = -2(y - (wx + b)) = -2 \\cdot (4 - 0) = -8 ]$\n",
    "\n",
    "4. **Update the parameters**:\n",
    "\n",
    "   $[ w_{\\text{new}} = w_{\\text{old}} - \\alpha \\frac{\\partial L}{\\partial w} = 0 - 0.01 \\cdot (-16) = 0.16 ]$\n",
    "\n",
    "   $[ b_{\\text{new}} = b_{\\text{old}} - \\alpha \\frac{\\partial L}{\\partial b} = 0 - 0.01 \\cdot (-8) = 0.08 ]$\n",
    "\n",
    "5. **Repeat** the process with the updated parameters until convergence.\n",
    "\n",
    "### Summary\n",
    "\n",
    "In gradient descent:\n",
    "- **Compute the gradient**: Use calculus to find the partial derivatives of the loss function with respect to each parameter.\n",
    "- **Update the parameters**: Adjust the parameters in the opposite direction of the gradient by a step size determined by the learning rate.\n",
    "- **Iterate**: Repeat the process until the loss function reaches its minimum or converges.\n",
    "\n",
    "Understanding the math behind gradient descent helps in tuning the algorithm effectively and diagnosing potential issues during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
