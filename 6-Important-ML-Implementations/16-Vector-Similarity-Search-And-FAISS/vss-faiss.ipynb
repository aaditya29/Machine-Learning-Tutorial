{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eb100d",
   "metadata": {},
   "source": [
    "# Beginner Friendly Guide to Vector Similarity Search and Facebook AI Similarity Search(FAISS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ff275",
   "metadata": {},
   "source": [
    "## 1. Embeddings: How Machines Understand Meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1f9b8",
   "metadata": {},
   "source": [
    "> Computers don't understand **zero** and **one** but they understant **0** and **1**.\n",
    "\n",
    "When we type *“king”* into a computer, it doesn’t see royalty but instead it sees a string of characters such as `['k', 'i', 'n', 'g']`. To a machine that’s meaningless because t doesn’t know that *“king”* and *“queen”* are related or that *“king”* and *“banana”* are not.\n",
    "\n",
    "So if machines can’t understand meaning directly then\n",
    "**how do modern AI models like ChatGPT or search engines make sense of language?**<br>\n",
    "The answer is that they turn words and sentences into **numbers** that *capture meaning* and these hese numerical representations are called **embeddings**.\n",
    "\n",
    "\n",
    "### How Meanings Live in Space\n",
    "\n",
    "Imagine we have a huge map but instead of cities we place **words** on it such as:\n",
    "\n",
    "* Words that mean similar things are close together.\n",
    "* Words that mean different things are far apart.\n",
    "\n",
    "On this map we notice that\n",
    "\n",
    "> *“king” and “queen” live close together.*\n",
    "> *“apple” and “banana” live close together.*\n",
    "> *But “king” and “banana”? They live far apart.*\n",
    "\n",
    "That’s the intuition behind **embeddings**.\n",
    "They are coordinates of words, phrases or sentences in a high-dimensional **semantic space**.\n",
    "\n",
    "Every point (vector) represents the meaning of the text.\n",
    "\n",
    "### From Words to Vectors\n",
    "\n",
    "In the early days, we used something called **one-hot encoding**:\n",
    "Each word was a long vector of 0s with a single 1 marking its position.\n",
    "\n",
    "For example:\n",
    "\n",
    "| Word   | One-hot vector (simplified) |\n",
    "| ------ | --------------------------- |\n",
    "| king   | [1, 0, 0, 0]                |\n",
    "| queen  | [0, 1, 0, 0]                |\n",
    "| apple  | [0, 0, 1, 0]                |\n",
    "| banana | [0, 0, 0, 1]                |\n",
    "\n",
    "This approach had a big problem:\n",
    "There are millions of words and all words are equally distant. There’s no sense of similarity between *“king”* and *“queen”*.\n",
    "\n",
    "### Enter Embeddings: Learning Meaning from Context\n",
    "\n",
    "Modern models (like Word2Vec, GloVe, and Transformer-based encoders) learn *dense* representations of words automatically by observing **context**.\n",
    "\n",
    "> The word *“bank”* in “river bank” vs. “bank account” appears in different neighborhoods.\n",
    "> The model learns those subtle differences.\n",
    "\n",
    "So instead of arbitrary one-hot vectors, we get something like:\n",
    "\n",
    "| Word   | Embedding (simplified)      |\n",
    "| ------ | --------------------------- |\n",
    "| king   | [0.61, 0.43, 0.72, 0.13, …] |\n",
    "| queen  | [0.59, 0.44, 0.70, 0.15, …] |\n",
    "| banana | [0.10, 0.87, 0.03, 0.91, …] |\n",
    "\n",
    "These numbers represent coordinates in a space where **distance = meaning difference**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca8996",
   "metadata": {},
   "source": [
    "### Embeddings in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adeea61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity(king, queen): 0.681\n",
      "Similarity(king, banana): 0.395\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a pre-trained embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create embeddings\n",
    "sentences = [\"king\", \"queen\", \"banana\"]\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Compute similarity between words\n",
    "sim_king_queen = util.cos_sim(embeddings[0], embeddings[1])\n",
    "sim_king_banana = util.cos_sim(embeddings[0], embeddings[2])\n",
    "\n",
    "print(f\"Similarity(king, queen): {sim_king_queen.item():.3f}\")\n",
    "print(f\"Similarity(king, banana): {sim_king_banana.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816bfeb",
   "metadata": {},
   "source": [
    "These numbers tells us that “king” and “queen” are close in meaning whereas “king” and “banana” are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f39d0c",
   "metadata": {},
   "source": [
    "### Why Embeddings Matter\n",
    "\n",
    "Embeddings are the unsung backbone of modern NLP. They are useful in the\n",
    "* **Semantic Search:** finding meaning-based matches, not just keyword matches.\n",
    "* **Recommendation Systems:** suggesting content similar in theme.\n",
    "* **Chatbots & RAG:** retrieving relevant documents before answering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538371b",
   "metadata": {},
   "source": [
    "## 2. Vector Similarity Search for Nearby Meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6eca2",
   "metadata": {},
   "source": [
    "### Vector Based Methods for Similarity Search\n",
    "\n",
    "Earlier we learned that embeddings place words and sentences into a vector space where distance represents meaning. Now we want to know **how do we find the closest vectors to a query?** or it can be also written as **how do we search for similar text?**\n",
    "\n",
    "#### TF-IDF\n",
    "Imagine you have three documents:\n",
    "1. **Doc A:** The dog saw the cat.\n",
    "2. **Doc B:** The cat sat on the mat.\n",
    "3. **Doc C:** A fast brown fox jumps over the lazy dog.\n",
    "Now if you want to find a document about a **dog** how would you do it?\n",
    "\n",
    "If you are dumb like me then your first instinct might be to just count the words. This is called a \"Bag of Words\" approach.\n",
    "- Doc A: `{\"the\": 2, \"dog\": 1, \"saw\": 1, \"cat\": 1}`\n",
    "- Doc C: `{\"a\": 1, \"fast\": 1, \"brown\": 1, \"fox\": 1, \"jumps\": 1, \"over\": 1, \"the\": 1, \"lazy\": 1, \"dog\": 1}`\n",
    "\n",
    "A query for \"the dog\" would give Doc A a score of 3 (2 for \"the\", 1 for \"dog\") and Doc C a score of 2 (1 for \"the\", 1 for \"dog\"). But the problem here is that word **the** is completely useless and it’s somehow dominating our scores. This is where IDF comes into picture. <br>\n",
    "\n",
    "TF-IDF transforms documents into vectors based on term frequency (TF) and inverse document frequency (IDF). In layman terms we can write it as like words that appear often in one document but rarely in others get higher weight (they are more meaningful).<br>\n",
    "A word that appears many times in one article is probably important to that article. If we are reading an article about Python and the word Python appears 30 times it's a safe bet the article is about the programming language or can be of snake also.<br>\n",
    "\n",
    "$TF(word, document) = (Count of the word in the document) / (Total words in the document)$\n",
    "\n",
    "Hence in our above example \"The dog saw the cat,\" the TF for \"dog\" is 1/5 = 0.2. The TF for \"the\" is 2/5 = 0.4.\n",
    "\n",
    "But as we notice \"the\" is still winning by far. We've only solved half the problem. Now for the secret sauce.\n",
    "\n",
    "#### Inverse Document Frequency (IDF): How Special is this Word?\n",
    "\n",
    "Inverse Document Frequency  asks a simple question that how common is this word across all our documents? For example, Rare words are special. They are strong signifiers of a topic. The word \"quantum\" or \"bioinformatics\" is a fantastic keyword. Common words are noise. The word \"it,\" \"and,\" or \"is\" appears in almost every document. It tells us nothing. IDF gives a high score to rare words and a low score to common words.<br>\n",
    "It's calculated like this:<br>\n",
    "$IDF(word, all_documents) = log( (Total number of documents) / (Number of documents containing the word) )$\n",
    "\n",
    "Now looking at our example:<br>\n",
    "Total documents = 3\n",
    "- IDF(\"dog\"): Appears in 2 documents `(A, C)` -> `log(3 / 2)` = 0.17\n",
    "- IDF(\"cat\"): Appears in 2 documents `(A, B)` -> `log(3 / 2)` = 0.17\n",
    "- IDF(\"fox\"): Appears in 1 document (C) -> `log(3 / 1)` = 0.47\n",
    "- IDF(the): Appears in 3 documents (A, B, C). -> log(3 / 3) = log(1) = **0**\n",
    "\n",
    "Now finally log(1) becomes 0 completely silencing the word \"the\" but \"fox\" which is unique to Doc C gets the highest score.\n",
    "\n",
    "Now we just multiply them together to get the final TF-IDF score for every word in every document.<br>\n",
    "$TF-IDF = TF * IDF$\n",
    "\n",
    "Number obtained from this score is high if and only if the word is common in this document (High TF) and the word is rare across all other documents (High IDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0a876",
   "metadata": {},
   "source": [
    "#### Implementing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b60f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"the dog saw the cat\".split()\n",
    "b = \"the cat saw the dog\".split()\n",
    "c = \"A fast brown fox jumps over the lazy dog.\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877d9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tfidf(word):\n",
    "    tf = []\n",
    "    count_n = 0\n",
    "    for sentence in [a, b, c]:\n",
    "        # calculate TF\n",
    "        t_count = len([x for x in sentence if word in sentence])\n",
    "        tf.append(t_count/len(sentence))\n",
    "        # count number of docs for IDF\n",
    "        count_n += 1 if word in sentence else 0\n",
    "    idf = np.log10(len([a, b, c]) / count_n)\n",
    "    return [round(_tf*idf, 2) for _tf in tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65bf7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF a: 0.18\n",
      "TF-IDF b: 0.18\n",
      "TF-IDF c: 0.0\n"
     ]
    }
   ],
   "source": [
    "tfidf_a, tfidf_b, tfidf_c = tfidf('dog')\n",
    "print(f\"TF-IDF a: {tfidf_a}\\nTF-IDF b: {tfidf_b}\\nTF-IDF c: {tfidf_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361191fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF a: 0.0\n",
      "TF-IDF b: 0.0\n",
      "TF-IDF c: 0.48\n"
     ]
    }
   ],
   "source": [
    "tfidf_a, tfidf_b, tfidf_c = tfidf('fox')\n",
    "print(f\"TF-IDF a: {tfidf_a}\\nTF-IDF b: {tfidf_b}\\nTF-IDF c: {tfidf_c}\")# changed word from 'dog' to 'forest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f5214",
   "metadata": {},
   "source": [
    "## 3. Facebook AI Similarity Search: How FAISS Finds a Needle in a Trillion Vector Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6852795a",
   "metadata": {},
   "source": [
    "In modern world everything is a vector. Our texts, photos or songs we hear we've gotten really good at turning them all into long lists of numbers called **embeddings.**<br>\n",
    "These vectors are powerful because they capture the meaning and context of the data. For example from BERT paper \"King\" - \"Man\" + \"Woman\" = \"Queen\" but it applies to everything.<br>\n",
    "- **Pictures:** Vectors for \"golden retriever in a park\" are \"close\" to vectors for \"dog on the grass.\"\n",
    "- **Text:** Vectors for \"How much is a flight to Tokyo?\" are \"close\" to \"Price of tickets to Japan.\"\n",
    "\n",
    "But this creates a new type of problem which we are calling **billion-vector problem**.<br>\n",
    "For example you are uploading a photo and we want to find he 10 most similar images then what is the most obvious nightmare choice?\n",
    "\n",
    "- Take the user's new image vector.\n",
    "- Compare it one by one to all the one billion vectors in our database (using a metric like Euclidean Distance or Cosine Similarity).\n",
    "- Sort the billion results by distance.\n",
    "- Return the top 10. \n",
    "\n",
    "This is called a brute-force or exhaustive search and it is completely accurate but it comes with a problem that it is also impossibly slow. You'd be waiting for minutes not milliseconds and if you are running a business then your users will leave then and servers will melt.<br>\n",
    "\n",
    "So what is solution of this? Here comes the **FAISS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6fb65",
   "metadata": {},
   "source": [
    "### 3.1 What is FAISS?\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is an open-source library from Meta AI. It's not a database but ultra fast toolbox written in C++ (with a perfect Python wrapper) for one and only job i.e. finding the **approximate nearest neighbors** in a massive set of vectors. The most important word here is **approximate**. FAISS is built on the concept that *what if we give up a tiny bit of perfect accuracy to gain an enormous amount of speed?*<br>\n",
    "For 99% of applications we don't need the absolute mathematically perfect 10 closest vectors but just need 10 really good matches. FAISS gives us those matches and it does it so fast that it feels like magic.\n",
    "\n",
    "- #### How FAISS Performs SMART Indexing: `IndexFlatL2`\n",
    "\n",
    "This is the dumb and slow method we talked about. FAISS has it and it's called IndexFlatL2 (Flat L2/Euclidean distance). It compares our query vector to every single other vector.\n",
    "- Speed: Very Slow.\n",
    "- Accuracy: 100% Perfect\n",
    "- Use Case: Only for small datasets (e.g., under 100,000 vectors) or for benchmarking other indexes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40975e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07d653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pair_ID\\tsentence_A\\tsentence_B\\trelatedness_score\\tentailment_judgment\\n1\\tA group of kids is playing in '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset initialization\n",
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "text = res.text\n",
    "text[:100]# show beginning of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d49fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(StringIO(text), sep='\\t')# load data into dataframe\n",
    "data.head()# show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c59b8308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of kids is playing in a yard and an old man is standing in the background',\n",
       " 'A group of children is playing in the house and there is no man standing in the background',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby',\n",
       " 'The kids are playing outdoors near a man with a smile',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data['sentence_A'].tolist()# extract sentences\n",
    "sentences[:5]# show first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c5bd4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_b = data['sentence_B'].tolist()# extract sentence B\n",
    "sentences.extend(sentence_b)# add to sentences list\n",
    "len(set(sentences))# unique sentences count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c22556",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]# additional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6a3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t',\n",
    "                       header=None, on_bad_lines='skip')\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71db1694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff0f8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our text files as backup\n",
    "sentences = [\n",
    "    sentence.replace('\\n', '') for sentence in list(set(sentences)) if type(sentence) is str\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4dcc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b13d7d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84651d2c8e494a42b1706a08a26ced44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12d10cabea740e0b349271148f64667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f50bebbb0b46e99bcbd7a034aa92ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ca8e5fca92415b92af59b77f54498c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1cb50133d54a96ba38ab9180e88c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a450046b9ec44a1283dec5e9bef4f391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911577d9090c4f8fb39b206eaefd749e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9dac5c1946413ebd9a8e54da0a44cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3a5bbca0ae4e0fa850fe98c585588f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2617ab6289e46188e7077591362fe5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30072989bf74d538208e211d1dafaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707b8821baab45bb81acb0938d307c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6685d0c6382c409c98ae0922117e9b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "sentence_embeddings = model.encode(sentences, convert_to_numpy=True, show_progress_bar=True)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d2e86c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape[0]# number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "277563ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "d# dimension of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdeceb6",
   "metadata": {},
   "source": [
    "#### Initialising `IndexFlatL2`\n",
    "\n",
    "Now we are initialising flat L2 distance index `IndexFlatL2` with vector dimension. Here we defined the dimension above which is 768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8add346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index now has 14504 vectors\n"
     ]
    }
   ],
   "source": [
    "# Reset the index to remove duplicates\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(sentence_embeddings)  # Add vectors only once\n",
    "print(f\"Index now has {index.ntotal} vectors\")  # Should show 14504"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6abd5",
   "metadata": {},
   "source": [
    "Usually indexes are required to train on our data before being used but `IndexFlatL2` is a simple operation and only requires that we calculate distances between vectors when we introduce our query vector `xq` during search. We can check this using `is_trained` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "147fb671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23d5e4",
   "metadata": {},
   "source": [
    "Now we will add new vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ac8dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)# adding new vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "841f8915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29008"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d11f8e",
   "metadata": {},
   "source": [
    "Now we have to give our search query and number of nearest neighbours(`k`) around which we want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cef99c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4# nearest neighbours to search\n",
    "xq = model.encode(\"The fox jumped over the dog.\")  # Returns shape (768,) search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "055cffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8121 22625   305 14809]]\n",
      "CPU times: user 3.92 ms, sys: 18.3 ms, total: 22.2 ms\n",
      "Wall time: 28.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Reshape query to 2D array with shape (1, 768)\n",
    "xq= np.asarray(xq, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "D, I = index.search(xq, k)  # actual search: returns (distances, indices)\n",
    "print(I)  # indexes of nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96a5f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8121: Two dogs running together and one has a duck toy in its mouth.',\n",
       " '22625: [index out of range]',\n",
       " '305: A greyhound jumps over a chain.',\n",
       " '14809: [index out of range]']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Safely display nearest neighbour sentences.\n",
    "# If I is not defined (previous search not run) perform the search.\n",
    "if 'I' not in globals():\n",
    "\t# ensure we have a query vector and k\n",
    "\tk = globals().get('k', 4)\n",
    "\tq = globals().get('xq2', globals().get('xq', None))\n",
    "\tif q is None:\n",
    "\t\traise RuntimeError(\"No query vector found. Define 'xq' or 'xq2' and run the search.\")\n",
    "\tq = np.asarray(q, dtype=np.float32).reshape(1, -1)\n",
    "\tD, I = index.search(q, k)\n",
    "\n",
    "# Build safe result list (handle out-of-range indices returned by faiss)\n",
    "results = []\n",
    "for idx in I[0]:\n",
    "\tif idx < 0 or idx >= len(sentences):\n",
    "\t\tresults.append(f'{idx}: [index out of range]')\n",
    "\telse:\n",
    "\t\tresults.append(f'{idx}: {sentences[idx]}')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15be3c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A greyhound jumps over a chain.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[305]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b306f9",
   "metadata": {},
   "source": [
    "We can see some good matches with little bit of similar contexts as our search query. Now we will extract the numerical vectors from FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d2a31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.zeros((k, d))# initialize array to hold vectors\n",
    "for i, val in enumerate(I[0].tolist()):# iterate over indices\n",
    "    vecs[i, :] = index.reconstruct(val)# extract vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e702b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c6492b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44295901,  0.0148984 ,  0.13510251,  0.17391756,  0.13312227,\n",
       "        0.38461047, -0.59615934, -0.74605459, -0.56400001, -0.40464091])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:10]### first 10 dimensions of first vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc6e8f",
   "metadata": {},
   "source": [
    "### Scaling Vector Search: Adding Partitioning to the Index\n",
    "\n",
    "Imagine we are running a semantic search engine with 100 million documents. A user types in a query and our system needs to find the most relevant documents. Using the flat index approach we learned earlier aboe (`IndexFlatL2`) our system would need to:\n",
    "1. Convert the query to a 768-dimensional vector.\n",
    "2. Calculate the distance between this query vector and all 100 million document vectors.\n",
    "3. Sort these distances to find the closest matches.\n",
    "\n",
    "That's 100 million distance calculations for every single search query. Even with optimized hardware this becomes painfully slow as our dataset grows. The core challenge here is that how do we search through millions (or billions) of vectors without comparing against every single one?\n",
    "Now here comes the clever mathematical concept called **Voronoi cells**.\n",
    "\n",
    "#### What Are Voronoi Cells?\n",
    "\n",
    "Imagine you're a city planner deciding where people should shop. You have three grocery stores in your city:\n",
    "- Store A at coordinates (2, 3).\n",
    "- Store B at coordinates (8, 7).\n",
    "- Store C at coordinates (5, 1).\n",
    "\n",
    "Only rule we have here is that every resident shops at whichever store is closest to their home.\n",
    "If we colour code the city map by which store each location is closest to we would create three regions. These regions are Voronoi cells.\n",
    "\n",
    "```bash\n",
    "      Store B (8,7)\n",
    "            ●\n",
    "           /|\\\n",
    "          / | \\\n",
    "         /  |  \\\n",
    "        /   |   \\\n",
    "       /    |    \\\n",
    "   Store A  |  Store C\n",
    "     (2,3)  |   (5,1)\n",
    "       ●    |      ●\n",
    "        \\   |     /\n",
    "         \\  |    /\n",
    "          \\ |   /\n",
    "           \\|  /\n",
    "            \\/\n",
    "```\n",
    "\n",
    "Each cell here share these properties:\n",
    "- One center point (the store location).\n",
    "- A boundary where we are equidistant from two stores.\n",
    "- Everything inside is closer to that store than any other.\n",
    "\n",
    "Now we will convert our this analogy to the vector search:\n",
    "- Instead of grocery stores we have centroid vectors (representative points in our vector space).\n",
    "- Instead of resident homes we have document embeddings.\n",
    "- Instead of asking which store? we ask which cell does this vector belong to?\n",
    "\n",
    "In high dimensional space (like the 768 dimensions in BERT embeddings) Voronoi cells work the same way. Each cell contains all vectors that are closer to its centroid than to any other centroid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a623a874",
   "metadata": {},
   "source": [
    "#### How FAISS Uses Voronoi Partitioning\n",
    "\n",
    "In FAISS we take our query vector `xq` identify which cell it belongs to and then use our `IndexFlatL2` to search between the query vector `xq` and all indexed vectors belonging to that cell. We can also include vectors from other nearby cells too.\n",
    "\n",
    "We initialize our new partitioned index by first adding our previous `IndexFlatL2` operation as a quantization step and feeding this into the new `IndexIVFFlat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be387c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
